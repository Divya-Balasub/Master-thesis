{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b13bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_directory = '/Users/divya/Documents/Data_collection/final_correct_dataset_with_default//'\n",
    "dataframes = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "big_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "big_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation - This reduced accuracy, so no need to run this\n",
    "column_min_max_values = {\n",
    "    'angle': (big_dataframe['angle'].min(), big_dataframe['angle'].max()),\n",
    "    'fsr1': (big_dataframe['fsr1'].min(), big_dataframe['fsr1'].max()),\n",
    "    'fsr2': (big_dataframe['fsr2'].min(), big_dataframe['fsr2'].max()),\n",
    "    'fsr3': (big_dataframe['fsr3'].min(), big_dataframe['fsr3'].max()),\n",
    "    'fsr4': (big_dataframe['fsr4'].min(), big_dataframe['fsr4'].max()),\n",
    "    'acc2x':(-15.0,15.0),\n",
    "    'acc2y':(-15.0,15.0),\n",
    "    'acc2z':(-15.0,15.0),\n",
    "    'gyro1':(-6.0,6.0),\n",
    "    'gyro2':(-6.0,6.0),\n",
    "    'gyro3':(-6.0,6.0),\n",
    "    #'orient1': (0, 350),\n",
    "    #'orient2': (0, 100),\n",
    "    #'orient3': (0, 100),\n",
    "}\n",
    "root_directory = '/Users/divya/Documents/Data_collection/final_correct_dataset_with_default//'\n",
    "dataframes = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            normalized_data = df.copy()\n",
    "            for column, (min_val, max_val) in column_min_max_values.items():\n",
    "                normalized_data[column] = (df[column] - min_val) / (max_val - min_val)\n",
    "            \n",
    "            dataframes.append(normalized_data)\n",
    "\n",
    "big_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "big_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is to select the 2 out of 4 FSRs for all the participants\n",
    "grouped_df = big_dataframe.groupby('participant')\n",
    "\n",
    "participant_column_mapping = {\n",
    "    1: ['fsr2', 'fsr4'],\n",
    "    2: ['fsr2', 'fsr4'],\n",
    "    3: ['fsr2', 'fsr4'],\n",
    "    4: ['fsr2', 'fsr4'],\n",
    "    5: ['fsr2', 'fsr4'],\n",
    "    6: ['fsr2', 'fsr4'],\n",
    "    9: ['fsr2', 'fsr4'],\n",
    "    10: ['fsr2', 'fsr3'],\n",
    "    11: ['fsr2', 'fsr4'],\n",
    "    12: ['fsr1', 'fsr3'],\n",
    "    13: ['fsr2', 'fsr4'],\n",
    "    14: ['fsr2', 'fsr3'],\n",
    "\n",
    "}\n",
    "big_dataframe['FSR1'] = ''\n",
    "big_dataframe['FSR2'] = ''\n",
    "\n",
    "for participant_id, cols_to_copy in participant_column_mapping.items():\n",
    "    mask = big_dataframe['participant'] == participant_id\n",
    "    big_dataframe.loc[mask, 'FSR1'] += big_dataframe.loc[mask, cols_to_copy[0]].astype(str) + ','\n",
    "    big_dataframe.loc[mask, 'FSR2'] += big_dataframe.loc[mask, cols_to_copy[1]].astype(str) + ','\n",
    "\n",
    "big_dataframe['FSR1'] = big_dataframe['FSR1'].str.rstrip(',')\n",
    "big_dataframe['FSR2'] = big_dataframe['FSR2'].str.rstrip(',')\n",
    "\n",
    "big_dataframe=big_dataframe.drop(columns=['fsr1','fsr2','fsr3','fsr4'])\n",
    "big_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe['FSR1'] = big_dataframe['FSR2'].astype(float)\n",
    "big_dataframe['FSR2'] = big_dataframe['FSR2'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98573f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set from all participants data\n",
    "\n",
    "grouped_dataframe = big_dataframe.groupby(['class', 'participant'])\n",
    "\n",
    "# Function to select 16 random serial numbers and corresponding rows\n",
    "def select_random_rows(group):\n",
    "    # Sample 16 random serial numbers\n",
    "    sampled_serial_numbers = group['serialnumber'].sample(n=17, replace=True, random_state=41).tolist()\n",
    "    \n",
    "    # Select all rows with the sampled serial numbers\n",
    "    selected_rows = group[group['serialnumber'].isin(sampled_serial_numbers)]\n",
    "    \n",
    "    return selected_rows\n",
    "\n",
    "\n",
    "test_set = grouped_dataframe.apply(select_random_rows).reset_index(drop=True)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5669cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_set without the data in test_set\n",
    "\n",
    "# Create a boolean mask to identify rows to be removed\n",
    "mask = big_dataframe.isin(test_set.to_dict('list')).all(axis=1)\n",
    "train_set = big_dataframe[~mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe =train_set\n",
    "test_dataframe = test_set\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = big_dataframe.groupby('serialnumber')['class'].first()\n",
    "y_test = test_dataframe.groupby('serialnumber')['class'].first()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = big_dataframe.drop(columns=['class','orient1','orient2','orient3','participant'])\n",
    "test = test_dataframe.drop(columns=['class','orient1','orient2','orient3','participant'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b00219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features\n",
    "# Extract features using tsfresh with 'id' column\n",
    "extracted_features = extract_relevant_features(X,y, column_id='serialnumber', column_sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "num_features_to_retain = 29\n",
    "\n",
    "# Apply mutual information feature selection\n",
    "feature_selector = SelectKBest(score_func=mutual_info_regression, k=num_features_to_retain)\n",
    "selected_features = feature_selector.fit_transform(extracted_features, y)\n",
    "\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Filter the original feature names to retain only selected features\n",
    "selected_feature_names = [extracted_features.columns[i] for i in selected_feature_indices]\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "selected_features_df = extracted_features[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = selected_features_df.drop('gyro3__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"', axis=1)\n",
    "selected_features_df = selected_features_df.drop('gyro3__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"var\"', axis=1)\n",
    "\n",
    "selected_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c82955",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_feature= pd.Index([\"FSR1__cid_ce__normalize_False\",'FSR1__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tsfresh.feature_extraction import feature_calculators as tsfresh_fc\n",
    "\n",
    "\n",
    "def generate_code(input_string,sets):\n",
    "    # Split the string using '__' as the delimiter\n",
    "    split_parts = re.split(\"__\", input_string)\n",
    "    \n",
    "    part1 = split_parts[0]\n",
    "    part2 = split_parts[1]\n",
    "\n",
    "    optional_params = {}\n",
    "    \n",
    "    for part in split_parts[2:]:\n",
    "\n",
    "        key, value = part.rsplit(\"_\", 1)\n",
    "        \n",
    "        if value.isdigit():\n",
    "            value = int(value)  # Convert to float if it's a number\n",
    "        elif value.lower() == \"true\":\n",
    "            value = True\n",
    "        elif value.lower() == \"false\":\n",
    "            value = False\n",
    "        optional_params[key] = value\n",
    "    \n",
    "    # Create the code snippet\n",
    "    code = (\n",
    "        f\"{sets}.groupby('serialnumber')['{part1}'].apply(lambda x: \"\n",
    "        f\"tsfresh_fc.{part2}(x, {', '.join([f'{key}={value}' for key, value in optional_params.items()])})).reset_index()\"\n",
    "    )\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for feature in f_feature:\n",
    "    \n",
    "    code = generate_code(feature,sets=\"X\")\n",
    "    \n",
    "    # Execute the code and store the result in a DataFrame\n",
    "    feature_result = eval(code)\n",
    "    feature_result.rename(columns={feature_result.columns[-1]: feature}, inplace=True)\n",
    "    \n",
    "    if new_df.empty:\n",
    "        new_df = feature_result\n",
    "    else:\n",
    "        new_df = pd.merge(new_df, feature_result, on='serialnumber', how='inner')\n",
    "new_df.set_index('serialnumber', inplace=True)\n",
    "\n",
    "selected_features_df=pd.concat([selected_features_df, new_df], axis=1)\n",
    "selected_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df.columns\n",
    "final_features = selected_features_df.columns\n",
    "final_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the selected features\n",
    "for feature in final_features:\n",
    "    sets=\"test\"\n",
    "    # Generate the code for the feature\n",
    "    if feature == 'gyro3__agg_linear_trend__attr_\"intercept\"__chunk_len_5__f_agg_\"var\"':\n",
    "        continue\n",
    "    if feature == 'gyro3__agg_linear_trend__attr_\"intercept\"__chunk_len___f_agg_\"var\"': \n",
    "        continue\n",
    "    code = generate_code(feature,sets)\n",
    "\n",
    "    feature_result = eval(code)\n",
    "    \n",
    "    # Rename the column to match the feature name\n",
    "    feature_result.rename(columns={feature_result.columns[-1]: feature}, inplace=True)\n",
    "\n",
    "    if result_df.empty:\n",
    "        result_df = feature_result\n",
    "    else:\n",
    "        result_df = pd.merge(result_df, feature_result, on='serialnumber', how='inner')\n",
    "\n",
    "result_df.set_index('serialnumber', inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.dropna()\n",
    "y_test = y_test.loc[result_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = selected_features_df \n",
    "y_train = y\n",
    "X_test = result_df\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8beb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "print(len(y))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report  # Add this import\n",
    "import numpy as np\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(classifier, X_train, y_train, cv=k)\n",
    "\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "# Predict on the test set\n",
    "dt_y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, dt_y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(classifier, filled=True, feature_names=X_train.columns, class_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(rf_classifier, X_train, y_train, cv=k)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = rf_classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boost\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=92, random_state=42)\n",
    "\n",
    "\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(gb_classifier, X_train, y_train, cv=k)\n",
    "\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = gb_classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(bagging_classifier, X_train, y_train, cv=k)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = bagging_classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0807b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a BaggingClassifier\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(adaboost_classifier, X_train, y_train, cv=k)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]] \n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = adaboost_classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "\n",
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(svm_classifier, X_train, y_train, cv=k)\n",
    "\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = svm_classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d839bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nearest neighbours KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "k = 10\n",
    "accuracy_scores = cross_val_score(knn_classifier, X_train, y_train, cv=k)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "single_instance = X_test.iloc[[3]] \n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = knn_classifier.predict(single_instance)\n",
    "\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
