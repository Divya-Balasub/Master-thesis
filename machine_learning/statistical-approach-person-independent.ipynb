{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_directory = '/Users/divya/Documents/Data_collection/final_correct_dataset_with_default//'\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "\n",
    "big_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "big_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is to select the 2 out of 4 FSRs for all the participants\n",
    "grouped_df = big_dataframe.groupby('participant')\n",
    "\n",
    "# Mapping of participant to the columns to copy\n",
    "participant_column_mapping = {\n",
    "    1: ['fsr2', 'fsr4'],\n",
    "    2: ['fsr2', 'fsr4'],\n",
    "    3: ['fsr2', 'fsr4'],\n",
    "    4: ['fsr2', 'fsr4'],\n",
    "    5: ['fsr2', 'fsr4'],\n",
    "    6: ['fsr2', 'fsr4'],\n",
    "    9: ['fsr2', 'fsr4'],\n",
    "    10: ['fsr2', 'fsr3'],\n",
    "    11: ['fsr2', 'fsr4'],\n",
    "    12: ['fsr1', 'fsr3'],\n",
    "    13: ['fsr2', 'fsr4'],\n",
    "    14: ['fsr2', 'fsr3'],\n",
    "\n",
    "}\n",
    "\n",
    "big_dataframe['FSR1'] = ''\n",
    "big_dataframe['FSR2'] = ''\n",
    "\n",
    "for participant_id, cols_to_copy in participant_column_mapping.items():\n",
    "    mask = big_dataframe['participant'] == participant_id\n",
    "    big_dataframe.loc[mask, 'FSR1'] += big_dataframe.loc[mask, cols_to_copy[0]].astype(str) + ','\n",
    "    big_dataframe.loc[mask, 'FSR2'] += big_dataframe.loc[mask, cols_to_copy[1]].astype(str) + ','\n",
    "\n",
    "big_dataframe['FSR1'] = big_dataframe['FSR1'].str.rstrip(',')\n",
    "big_dataframe['FSR2'] = big_dataframe['FSR2'].str.rstrip(',')\n",
    "\n",
    "big_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe['FSR1'] = big_dataframe['FSR2'].astype(float)\n",
    "big_dataframe['FSR2'] = big_dataframe['FSR2'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe=big_dataframe.drop(columns=['fsr1','fsr2','fsr3','fsr4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_participants = [1, 2, 3, 4, 5, 6, 9, 12, 13]\n",
    "test_participants = [10, 11, 14]\n",
    "\n",
    "train_set = big_dataframe[big_dataframe['participant'].isin(train_participants)].copy()\n",
    "test_set = big_dataframe[big_dataframe['participant'].isin(test_participants)].copy()\n",
    "big_dataframe =train_set\n",
    "test_dataframe = test_set\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21187cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = big_dataframe.groupby('serialnumber')['class'].first()\n",
    "y_test = test_dataframe.groupby('serialnumber')['class'].first()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bea1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = big_dataframe.drop(columns=['class','orient1','orient2','orient3','participant'])\n",
    "test = test_dataframe.drop(columns=['class','orient1','orient2','orient3','participant'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b00219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features\n",
    "extracted_features = extract_relevant_features(X,y, column_id='serialnumber', column_sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# Number of features you want to retain\n",
    "num_features_to_retain = 29\n",
    "\n",
    "# Apply mutual information feature selection\n",
    "feature_selector = SelectKBest(score_func=mutual_info_regression, k=num_features_to_retain)\n",
    "selected_features = feature_selector.fit_transform(extracted_features, y)\n",
    "\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Filter the original feature names to retain only selected features\n",
    "selected_feature_names = [extracted_features.columns[i] for i in selected_feature_indices]\n",
    "\n",
    "# Create a DataFrame with the selected features\n",
    "selected_features_df = extracted_features[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = selected_features_df.drop('gyro3__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"var\"', axis=1)\n",
    "#selected_features_df = selected_features_df.drop('gyro3__fft_aggregated__aggtype_\"skew\"', axis=1)\n",
    "\n",
    "selected_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_feature= pd.Index([\"FSR1__cid_ce__normalize_False\",'FSR1__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0332c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tsfresh.feature_extraction import feature_calculators as tsfresh_fc\n",
    "\n",
    "def generate_code(input_string,sets):\n",
    "    # Split the string using '__' as the delimiter\n",
    "    split_parts = re.split(\"__\", input_string)\n",
    "    \n",
    "    part1 = split_parts[0]\n",
    "    part2 = split_parts[1]\n",
    "    \n",
    "    optional_params = {}\n",
    "    \n",
    "    for part in split_parts[2:]:\n",
    "\n",
    "        key, value = part.rsplit(\"_\", 1)\n",
    "        \n",
    "        if value.isdigit():\n",
    "            value = int(value)\n",
    "        elif value.lower() == \"true\":\n",
    "            value = True\n",
    "        elif value.lower() == \"false\":\n",
    "            value = False\n",
    "        #if key == \"f_agg\":\n",
    "            # Replace the second underscore with an equal sign in f_agg parameter\n",
    "          #  value = f'\"{value.replace(\"_\", \"=\")}\"'\n",
    "        optional_params[key] = value\n",
    "    \n",
    "    # Create the code snippet\n",
    "    code = (\n",
    "        f\"{sets}.groupby('serialnumber')['{part1}'].apply(lambda x: \"\n",
    "        f\"tsfresh_fc.{part2}(x, {', '.join([f'{key}={value}' for key, value in optional_params.items()])})).reset_index()\"\n",
    "    )\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for feature in f_feature:\n",
    "    \n",
    "    code = generate_code(feature,sets=\"X\")\n",
    "    \n",
    "    # Execute the code and store the result in a DataFrame\n",
    "    feature_result = eval(code)\n",
    "    \n",
    "    # Rename the column to match the feature name\n",
    "    feature_result.rename(columns={feature_result.columns[-1]: feature}, inplace=True)\n",
    "    \n",
    "    # Merge the result into the main DataFrame\n",
    "    if new_df.empty:\n",
    "        new_df = feature_result\n",
    "    else:\n",
    "        new_df = pd.merge(new_df, feature_result, on='serialnumber', how='inner')\n",
    "new_df.set_index('serialnumber', inplace=True)\n",
    "\n",
    "selected_features_df=pd.concat([selected_features_df, new_df], axis=1)\n",
    "selected_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df.columns\n",
    "final_features = selected_features_df.columns\n",
    "final_features = final_features.append(pd.Index([\"fsr2__cid_ce__normalize_False\"]))\n",
    "final_features = final_features.append(pd.Index(['fsr2__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.0']))\n",
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c79dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the selected features\n",
    "for feature in final_features:\n",
    "    sets=\"test\"\n",
    "    # Generate the code for the feature\n",
    "    if feature == 'gyro3__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"var\"':\n",
    "        continue\n",
    "        \n",
    "    if feature == 'gyro3__fft_aggregated__aggtype_\"skew\"': \n",
    "        continue\n",
    "    code = generate_code(feature,sets)\n",
    "    # Execute the code and store the result in a DataFrame\n",
    "    feature_result = eval(code)\n",
    "    \n",
    "    # Rename the column to match the feature name\n",
    "    feature_result.rename(columns={feature_result.columns[-1]: feature}, inplace=True)\n",
    "    \n",
    "    # Merge the result into the main DataFrame\n",
    "    if result_df.empty:\n",
    "        result_df = feature_result\n",
    "    else:\n",
    "        result_df = pd.merge(result_df, feature_result, on='serialnumber', how='inner')\n",
    "\n",
    "# Set 'serialnumber' as the index of the result DataFrame\n",
    "result_df.set_index('serialnumber', inplace=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.dropna()\n",
    "y_test = y_test.loc[result_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = selected_features_df \n",
    "y_train = y\n",
    "X_test = result_df\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8beb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print(len(y))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70505191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create the DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "\n",
    "# Calculate the average accuracy\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]  # Adjust to the instance you want to predict\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = classifier.predict(single_instance)\n",
    "# Calculate the single prediction time\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "# Predict on the test set\n",
    "dt_y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate a classification report and accuracy for the test set\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, dt_y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))  # Adjust the figure size as needed\n",
    "plot_tree(classifier, filled=True, feature_names=X_train.columns, class_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(rf_classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = rf_classifier.predict(single_instance)\n",
    "# Calculate the single prediction time\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74894d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "class_labels = [\"Default\",\"Stop\", \"Speed_Up\", \"Slow_Down\", \"Change_Direction\", \"Repeat\", \"Reset\"]\n",
    "# Define a mapping from numeric labels to class names\n",
    "label_mapping = {\n",
    "    0: \"Default\",\n",
    "    1: \"Stop\",\n",
    "    2: \"Speed_Up\",\n",
    "    3: \"Slow_Down\",\n",
    "    4: \"Change_Direction\",\n",
    "    5: \"Repeat\",\n",
    "    6: \"Reset\"\n",
    "}\n",
    "\n",
    "y_test_mapped = [label_mapping[label] for label in y_test]\n",
    "y_pred_mapped = [label_mapping[label] for label in y_pred]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_mapped, y_pred_mapped, labels=class_labels)\n",
    "\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48a263",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Gradient Boost\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=92, random_state=42,max_depth=4,learning_rate=0.2)\n",
    "\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(gb_classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = gb_classifier.predict(single_instance)\n",
    "# Calculate the single prediction time\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for gradient boost model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=66)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mapped = [label_mapping[label] for label in y_test]\n",
    "y_pred_mapped = [label_mapping[label] for label in y_pred]\n",
    "conf_matrix = confusion_matrix(y_test_mapped, y_pred_mapped, labels=class_labels)\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854a0c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_mapped, y_pred_mapped, labels=class_labels)\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "confusion_df_percent = confusion_df.divide(confusion_df.sum(axis=1), axis=0) * 100\n",
    "annotations = confusion_df.astype(str) + '\\n' + confusion_df_percent.round(2).astype(str) + '%'\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_df, annot=annotations, fmt='', cmap=\"Blues\", cbar_kws={'label': 'Counts'})\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig('conf-gb.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier(n_estimators=120, random_state=42,max_depth=4,learning_rate=0.2)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(bagging_classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]] \n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = bagging_classifier.predict(single_instance)\n",
    "\n",
    "# Calculate the single prediction time\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0807b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a BaggingClassifier\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(adaboost_classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "\n",
    "# Calculate the average accuracy\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = adaboost_classifier.predict(single_instance)\n",
    "# Calculate the single prediction time\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58fc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(svm_classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = svm_classifier.predict(single_instance)\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d839bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nearest neighbours KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "groups = big_dataframe.groupby('serialnumber')['participant'].first()\n",
    "logo = LeaveOneGroupOut()\n",
    "accuracy_scores = cross_val_score(knn_classifier, X_train, y_train, groups=groups, cv=logo)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"Accuracy scores for each fold:\", accuracy_scores)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "start_time = time.time()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Predict on a single instance to measure single prediction time\n",
    "single_instance = X_test.iloc[[3]]\n",
    "start_time_single_prediction = time.time()\n",
    "single_prediction = knn_classifier.predict(single_instance)\n",
    "# Calculate the single prediction time\n",
    "single_prediction_time = time.time() - start_time_single_prediction\n",
    "print(\"Single Prediction time:\", single_prediction_time, \"seconds\")\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for gradient boost model\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid you want to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform the grid search on your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "best_estimator.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on the test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for Ada boost model\n",
    "\n",
    "# Create the base classifier\n",
    "base_classifier = GradientBoostingClassifier(n_estimators=92, random_state=42)\n",
    "#base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create the AdaBoost classifier\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, random_state=42)\n",
    "\n",
    "# Define the parameter grid you want to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=adaboost_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on the test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_classifier = GradientBoostingClassifier(n_estimators=92, random_state=42)\n",
    "base_classifier = RandomForestClassifier(n_estimators=40, random_state=42)\n",
    "\n",
    "# Create the AdaBoost classifier\n",
    "adaboost_classifier = AdaBoostClassifier(base_classifier, learning_rate =0.001, random_state=42)\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = adaboost_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for Bagging model\n",
    "\n",
    "# Create the base classifier\n",
    "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, random_state=42)\n",
    "\n",
    "# Define the parameter grid you want to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_samples': [0.5, 0.7, 0.9],\n",
    "    'max_features': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=bagging_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform the grid search on your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator to make predictions on the test data\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on the test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13849075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading best model\n",
    "import joblib\n",
    "joblib.dump(gb_classifier, 'gb_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for best model\n",
    "best_model = gb_classifier\n",
    "\n",
    "y_test_mapped = [label_mapping[label] for label in y_test]\n",
    "y_pred_mapped = [label_mapping[label] for label in y_pred]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_mapped, y_pred_mapped, labels=class_labels)\n",
    "\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4878603",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test_mapped, y_pred_mapped, labels=class_labels)\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "confusion_df_percent = confusion_df.divide(confusion_df.sum(axis=1), axis=0) * 100\n",
    "annotations = confusion_df.astype(str) + '\\n' + confusion_df_percent.round(2).astype(str) + '%'\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_df, annot=annotations, fmt='', cmap=\"Blues\", cbar_kws={'label': 'Counts'})\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig('conf-gb.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
